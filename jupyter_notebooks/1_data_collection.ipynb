{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corals health monitoring project\n",
    "## Data collection and cleaning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect dataset from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives:\n",
    "* Collect data\n",
    "* Clean data (remove files which are not images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input:\n",
    "* Kaggle autentication token (kaggle.json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output:\n",
    "* Generate dataset:<br>\n",
    "inputs/corals-dataset/Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r /workspace/corals_health/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/corals_health/jupyter_notebooks'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current working directory is:\n",
      " /workspace/corals_health\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/workspace/corals_health')\n",
    "print(f\"Your current working directory is:\\n {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the Kaggle configuration directory to the current working directory and set permissions for the Kaggle authentication JSON\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "! chmod 600 kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the dataset path from the [Kaggle URL](https://www.kaggle.com/datasets/sonainjamil/bhd-corals).\n",
    "* Set your destination folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Kaggle dataset summary page](../assets/images/kaggle-dataset.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Kaggle Dataset and Download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/sonainjamil/bhd-corals\n",
      "License(s): Attribution 4.0 International (CC BY 4.0)\n",
      "Downloading bhd-corals.zip to /workspace/corals_health/inputs/corals-dataset\n",
      " 91%|████████████████████████████████████▏   | 113M/125M [00:03<00:00, 36.0MB/s]\n",
      "100%|████████████████████████████████████████| 125M/125M [00:03<00:00, 36.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "KaggleDatasetPath = \"sonainjamil/bhd-corals\"\n",
    "DestinationFolder = \"/workspace/corals_health/inputs/corals-dataset\"   \n",
    "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unzip the downloaded file, and delete the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(DestinationFolder + '/bhd-corals.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(DestinationFolder)\n",
    "\n",
    "os.remove(DestinationFolder + '/bhd-corals.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "### In the '/inputs/' folder, check which files are not images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def remove_non_image_file(my_data_dir):\n",
    "    image_extension = ('.png', '.jpg', '.jpeg')\n",
    "    folders = os.listdir(my_data_dir)\n",
    "    for folder in folders:\n",
    "        files = os.listdir(my_data_dir + '/' + folder)\n",
    "        i = []\n",
    "        j = []\n",
    "        for given_file in files:\n",
    "            if not given_file.lower().endswith(image_extension):\n",
    "                file_location = my_data_dir + '/' + folder + '/' + given_file\n",
    "                print(file_location)\n",
    "                os.remove(file_location)  # remove non image file\n",
    "                i.append(1)\n",
    "            else:\n",
    "                j.append(1)\n",
    "                pass\n",
    "        print(f\"Folder: {folder} - has image file\", len(j))\n",
    "        print(f\"Folder: {folder} - has non-image file\", len(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: Bleached - has image file 720\n",
      "Folder: Bleached - has non-image file 0\n",
      "Folder: Dead - has image file 150\n",
      "Folder: Dead - has non-image file 0\n",
      "Folder: Healthy - has image file 712\n",
      "Folder: Healthy - has non-image file 0\n"
     ]
    }
   ],
   "source": [
    "remove_non_image_file(my_data_dir='/workspace/corals_health/inputs/corals-dataset/Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove black and white images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_black_white (my_data_dir):\n",
    "    folders = os.listdir(my_data_dir)\n",
    "    print(folders)\n",
    "    for folder in folders:\n",
    "        files = os.listdir(my_data_dir + '/' + folder)\n",
    "        for given_image in files:\n",
    "            count = 0\n",
    "            image = imread(os.path.join(my_data_dir, folder, given_image))\n",
    "            if len(image.shape) == 3:\n",
    "                pass\n",
    "            else:\n",
    "                os.remove(os.path.join(my_data_dir, folder, given_image))      \n",
    "                count += 1\n",
    "    print(f\"{count} black-white images were detected and removed.\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bleached', 'Dead', 'Healthy']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 black-white images were detected and removed.\n"
     ]
    }
   ],
   "source": [
    "remove_black_white(my_data_dir='/workspace/corals_health/inputs/corals-dataset/Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train validation test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# replace string concatenation with path builders\n",
    "\n",
    "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
    "\n",
    "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
    "        print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum to 1.0\")\n",
    "        return\n",
    "\n",
    "    # gets classes labels\n",
    "    labels = os.listdir(my_data_dir)  # it should get only the folder name\n",
    "    print(labels)\n",
    "    if 'test' in labels:\n",
    "        pass\n",
    "    else:\n",
    "        # create train, test folders with classes labels sub-folder\n",
    "        for folder in ['train', 'validation', 'test']:\n",
    "            for label in labels:\n",
    "                os.makedirs(name=my_data_dir + '/' + folder + '/' + label)\n",
    "\n",
    "        for label in labels:\n",
    "\n",
    "            files = os.listdir(my_data_dir + '/' + label)\n",
    "            random.shuffle(files)\n",
    "\n",
    "            train_set_files_qty = int(len(files) * train_set_ratio)\n",
    "            validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
    "\n",
    "            count = 1\n",
    "            for file_name in files:\n",
    "                if count <= train_set_files_qty:\n",
    "                    # move a given file to the train set\n",
    "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
    "                                my_data_dir + '/train/' + label + '/' + file_name)\n",
    "\n",
    "                elif count <= (train_set_files_qty + validation_set_files_qty):\n",
    "                    # move a given file to the validation set\n",
    "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
    "                                my_data_dir + '/validation/' + label + '/' + file_name)\n",
    "\n",
    "                else:\n",
    "                    # move given file to test set\n",
    "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
    "                                my_data_dir + '/test/' + label + '/' + file_name)\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            os.rmdir(my_data_dir + '/' + label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bleached', 'Dead', 'Healthy']\n"
     ]
    }
   ],
   "source": [
    "split_train_validation_test_images(my_data_dir=f\"/workspace/corals_health/inputs/corals-dataset/Dataset\",\n",
    "                                   train_set_ratio=0.7,\n",
    "                                   validation_set_ratio=0.1,\n",
    "                                   test_set_ratio=0.2\n",
    "                                   )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
