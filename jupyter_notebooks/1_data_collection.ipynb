{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corals health monitoring project\n",
    "## Data collection and cleaning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect dataset from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives:\n",
    "* Collect data\n",
    "* Clean data (remove files which are not images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input:\n",
    "* Kaggle autentication token (kaggle.json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output:\n",
    "* Generate dataset:<br>\n",
    "inputs/corals-dataset/Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES\n",
    "##### ** During model fitting it was discovered that the dataset contained some images in wrong folders. Namely, many images of dead corals were found in bleached, bleached corals were found in healthy. In order to reduce error during model training, validation and prediction, the dataset was inspected visually and the most obvious images (obviously dead, bleached or healthy were moved to corresponding folders).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r /workspace/corals_health/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/corals_health/jupyter_notebooks'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current working directory is:\n",
      " /workspace/corals_health\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/workspace/corals_health')\n",
    "print(f\"Your current working directory is:\\n {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the Kaggle configuration directory to the current working directory and set permissions for the Kaggle authentication JSON\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "! chmod 600 kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the dataset path from the [Kaggle URL](https://www.kaggle.com/datasets/sonainjamil/bhd-corals).\n",
    "* Set your destination folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Kaggle dataset summary page](../assets/images/kaggle-dataset.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Kaggle Dataset and Download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/sonainjamil/bhd-corals\n",
      "License(s): Attribution 4.0 International (CC BY 4.0)\n",
      "Downloading bhd-corals.zip to /workspace/corals_health/inputs/corals-dataset\n",
      " 91%|████████████████████████████████████▏   | 113M/125M [00:03<00:00, 36.0MB/s]\n",
      "100%|████████████████████████████████████████| 125M/125M [00:03<00:00, 36.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "KaggleDatasetPath = \"sonainjamil/bhd-corals\"\n",
    "DestinationFolder = \"/workspace/corals_health/inputs/corals-dataset\"   \n",
    "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unzip the downloaded file, and delete the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(DestinationFolder + '/bhd-corals.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(DestinationFolder)\n",
    "\n",
    "os.remove(DestinationFolder + '/bhd-corals.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "### In the '/inputs/' folder, check which files are not images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def remove_non_image_file(my_data_dir):\n",
    "    image_extension = ('.png', '.jpg', '.jpeg')\n",
    "    folders = os.listdir(my_data_dir)\n",
    "    for folder in folders:\n",
    "        files = os.listdir(my_data_dir + '/' + folder)\n",
    "        i = []\n",
    "        j = []\n",
    "        for given_file in files:\n",
    "            if not given_file.lower().endswith(image_extension):\n",
    "                file_location = my_data_dir + '/' + folder + '/' + given_file\n",
    "                print(file_location)\n",
    "                os.remove(file_location)  # remove non image file\n",
    "                i.append(1)\n",
    "            else:\n",
    "                j.append(1)\n",
    "                pass\n",
    "        print(f\"Folder: {folder} - has image file\", len(j))\n",
    "        print(f\"Folder: {folder} - has non-image file\", len(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: Healthy - has image file 661\n",
      "Folder: Healthy - has non-image file 0\n",
      "Folder: Bleached - has image file 648\n",
      "Folder: Bleached - has non-image file 0\n",
      "Folder: Dead - has image file 161\n",
      "Folder: Dead - has non-image file 0\n"
     ]
    }
   ],
   "source": [
    "remove_non_image_file(my_data_dir='/workspace/corals_health/inputs/corals-dataset/Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove black and white images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_black_white (my_data_dir):\n",
    "    folders = os.listdir(my_data_dir)\n",
    "    print(folders)\n",
    "    for folder in folders:\n",
    "        files = os.listdir(os.path.join(my_data_dir, folder))\n",
    "        for given_image in files:\n",
    "            count = 0\n",
    "            image = imread(os.path.join(my_data_dir, folder, given_image))\n",
    "            if len(image.shape) == 3:\n",
    "                pass\n",
    "            else:\n",
    "                os.remove(os.path.join(my_data_dir, folder, given_image))      \n",
    "                count += 1\n",
    "    print(f\"{count} black-white images were detected and removed.\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Healthy', 'Bleached', 'Dead']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 black-white images were detected and removed.\n"
     ]
    }
   ],
   "source": [
    "remove_black_white(my_data_dir='/workspace/corals_health/inputs/corals-dataset/Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual data check\n",
    "The dataset used in this work was assembled and preprocessed in the context of the project, published by [Jamil <em>et al.</em>](https://www.mdpi.com/2504-2289/5/4/53). Although, the [dataset](https://www.kaggle.com/datasets/sonainjamil/bhd-corals) of coral images is labelled as 'Healthy', 'Bleached' and 'Dead', the work was focused on distinguishing beween 'Healthy' and 'Bleached' (binary classification task) using 'specific deep convolutional neural networks such as AlexNet, GoogLeNet, VGG-19, ResNet-50, Inception v3, and CoralNet. (c)' The subset labelled as 'Dead' was treated as 'Bleached'. Attempt to train the model to categorise the data into three groups: 'Bleached', 'Dead' and 'Healthy' resulted in poor genaralisation and overfitting. Manual inspection of the dataset revealed that some of the 'Dead' corals were labelled as 'Bleached' and the other way around. Futhermore, some of the 'Bleached' corals were marked as 'Healthy'. This image misplacement may be less critical for binary classification, but crucial for training models for more categories. Therefore, the author had to manually move some images in downloaded dataset where the misplacement was obvous, into more appropriate folders, following the [description](https://en.wikipedia.org/wiki/Coral_bleaching)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train validation test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "\n",
    "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
    "\n",
    "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
    "        print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum to 1.0\")\n",
    "        return\n",
    "\n",
    "    # gets classes labels\n",
    "    labels = os.listdir(my_data_dir)  # it should get only the folder name\n",
    "    print(labels)\n",
    "    if 'test' in labels:\n",
    "        pass\n",
    "    else:\n",
    "        # create train, test folders with classes labels sub-folder\n",
    "        for folder in ['train', 'validation', 'test']:\n",
    "            for label in labels:\n",
    "                os.makedirs(os.path.join(my_data_dir, folder, label))\n",
    "\n",
    "        for label in labels:\n",
    "\n",
    "            files = os.listdir(os.path.join(my_data_dir, label))\n",
    "            random.shuffle(files)\n",
    "\n",
    "            train_set_files_qty = int(len(files) * train_set_ratio)\n",
    "            validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
    "\n",
    "            count = 1\n",
    "            for file_name in files:\n",
    "                if count <= train_set_files_qty:\n",
    "                    # move a given file to the train set\n",
    "                    shutil.move(os.path.join(my_data_dir, label, file_name), os.path.join(\n",
    "                                my_data_dir, 'train', label, file_name))\n",
    "\n",
    "                elif count <= (train_set_files_qty + validation_set_files_qty):\n",
    "                    # move a given file to the validation set\n",
    "                    shutil.move(os.path.join( my_data_dir, label, file_name), os.path.join(\n",
    "                                my_data_dir, 'validation', label, file_name))\n",
    "\n",
    "                else:\n",
    "                    # move given file to test set\n",
    "                    shutil.move(os.path.join(my_data_dir, label, file_name), os.path.join(\n",
    "                                my_data_dir, 'test', label, file_name))\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            os.rmdir(os.path.join(my_data_dir,label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Healthy', 'Bleached', 'Dead']\n"
     ]
    }
   ],
   "source": [
    "split_train_validation_test_images(my_data_dir=f\"/workspace/corals_health/inputs/corals-dataset/Dataset\",\n",
    "                                   train_set_ratio=0.7,\n",
    "                                   validation_set_ratio=0.1,\n",
    "                                   test_set_ratio=0.2\n",
    "                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
